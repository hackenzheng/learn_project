## 主键和外键

关系型数据库不能设置两个主键,但可以将两个字段的组合作为一个主键即联合主键.主键是唯一区分,与唯一约束是有区别的,主键一张表只有一个,可以做外键,不能为空，唯一约束可以有多个，主要用来约束字段的唯一性.
外健是关联的数据,联表查询有无外键都可以, update的作为外键的主键的value时或删除主键的记录时,会做关联检查,具体的约束规则可以设置,比如是不允许更新或删除,或者是全部更新或删除,用于保证数据的完整性和一致性,
外键的意义：用于与其他表建立连接，用于预防破坏表之间的链接；防止非法数据插入到外键列，因为要插入的值必须已经是在其他表中的主键出现了才行。
数据库支持事物,支持外键,那么一致性在数据库服务器完成, 如果数据库不支持但又要处理事务就要在在业务代码中完成.
在并发不大压力不大时,可以使用外键,减小开发工作量,很多业务逻辑上的校验不用写代码完成.
但如果互联网行业并发大的时候一般不使用,因为数据库服务器做关联性检查会拖慢数据库的速度.而应用服务器是可以方便扩展的.

互联网场景下数据规模大的时候一般不会用外键，因为用了外键数据库要做很多的关联检查，加重了负载。

创建表的时候很容易字段里面出现空格，建好之后用desc table一下，查看是否有多的空格，不然插入数据会失败。SQL操作时，若字段是关键字，需要单引号转义。

主键和唯一性约束都能保证某个列或者列组合的唯一性，但是：

    一张表中只能定义一个主键，却可以定义多个唯一性约束！
    主键列不允许存放NULL值，而普通的唯一性约束列可以存放NULL值！
    可以多个列组合成主键
    
自增列：

    一个表中最多有一个递增列。
    一般只为整数类型的列定义递增属性，浮点数类型基本不用递增属性。
    具有AUTO_INCREMENT属性的列必须建立索引。主键和具有唯一性约束的列会自动建立索引
    一般递增列都是作为主键的属性，来自动生成唯一标识一个记录的主键值。
    因为具有AUTO_INCREMENT属性的列是从1开始递增的，所以最好用UNSIGNED来修饰这个列，可以提升正数的表示范围。
    

union(联合查询)：被合并的各个查询的查询对象个数必须相同；查询的结果集中显示的列名将以第一个查询中的列名为准；各个查询语句中的查询列表的类型兼容就可以。
union是在竖直方向上合并，字段只跟第一个保持一致。 join是在水平方向合并，字段是两个join字句的并集。
https://blog.csdn.net/ljxfblog/article/details/52066006

## 索引
索引：b树和b+树都是多路平衡搜索树，b树是非叶子节点也会存储数据，b+树只有最后的叶子节点存储数据，用b+树索引是相对于b树每个节点存储的索引信息会更多，
因为不用存储数据。为了方便批量查询，b+树的叶子节点会通过指针连接起来。

常见三种索引对比：

    哈希存储引擎：是哈希表的持久化实现，支持增、删、改以及随机读取操作，但不支持顺序扫描，对于key-value的插入以及查询，
    哈希表的复杂度都是O(1)，明显比树的操作O(n)快,如果不需要有序的遍历数据，可以考虑hash表。但hash表要一次全部加载到内存，容量有限制。
    
    B树存储引擎是B树的持久化实现，不仅支持单条记录的增、删、读、改操作，还支持顺序扫描（B+树的叶子节点之间的指针，B树不支持，因为每个节点都有数据，当然也可以中序便利的方式实现）
    
    LSM树（Log-Structured Merge Tree）存储引擎和B树存储引擎一样，同样支持增、删、读、改、顺序扫描操作。
    而且通过批量存储技术规避磁盘随机写入问题。LSM树和B+树相比，LSM树牺牲了部分读性能，用来大幅提高写性能。
    通过缓存，先将数据写入到内存，同时用日志持久化，因为日志是顺序写入，比随机写入快。然后再进行合并，合并的时候会优化，将逻辑上相邻的数据物理上也相邻，
    这样避免了随机写入和页分裂，提高写的性能。读取时可能需要先看是否命中内存，否则需要访问较多的磁盘文件。
    hbase的存储用的就是lsm树，会将写入的数据先在内存里面排完序之后才会写入到磁盘，使逻辑上相邻的数据在磁盘上也尽量相邻。
    <从LSM Tree到HBase> http://leonlibraries.github.io/2017/05/18/%E4%BB%8ELSM%E5%88%B0HBase/
B+树相比于B树：

    （1) B+tree的磁盘读写代价更低
        B+tree的内部结点并没有指向关键字具体信息的指针。因此其内部结点相对B树更小。如果把所有同一内部结点的关键字存放在同一盘块中，
        那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。
    
    （2）B+tree的查询效率更加稳定
        由于非叶子结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。
        
    （3）B树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。正是为了解决这个问题，B+树应运而生。
        B+树只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作（或者说效率太低）。
        
     但B+树的缺点：
     B+树最大的性能问题是会产生大量的随机IO，随着新数据的插入，叶子节点会慢慢分裂，逻辑上连续的叶子节点在物理上往往不连续，甚至分离的很远，
     但做范围查询时，会产生大量读随机IO。对于大量的随机写也一样，举一个插入key跨度很大的例子，如7->1500->3->2000 ... 
     逻辑上7和3,1500和2000是比较近，最好挨着放，但b+树只会根据写入顺序存，导致新插入的数据存储在磁盘上相隔很远，会产生大量的随机写IO.
     


innodb引擎：

    如果给主键设置了索引就用主键创建主键索引，如果没有就默认以rowid创建索引。主键索引是聚簇索引，最后的叶子节点会存储具体的数据。
    其他字段建的索引都是非聚簇索引，叶子节点不存数据，而是指向主键索引的节点(具体就是主键的值)。这样直接从索引取数据而非从磁盘的文件中取数据。　
    比如id是主键，age是普通索引，走非主键age的查询过程是：索引先根据age搜索等于18的索引记录，找到ID=10的记录，然后再到主键索引搜索一次，然后拿出需要查询的数据。
    从普通索引查出主键索引，然后查询出数据的过程叫做回表。由于回表需要多执行一次查询，这也是为什么主键索引要比普通索引要快的原因，所以，我们要尽量使用主键查询。
    
    非主键索引也被称为二级索引，drop主键索引会导致其他索引失效,但drop普通索引不会
    那相当于存储两份数据，占的空间不是很大？
    
    覆盖索引：要查询的字段都建了索引，就叫做“覆盖索引”。这样的话查询的数据直接从索引中取，不需要在走主键索引树。

主键尽量使用自增主键而非UUID：

    使用自增主键时，每次插入一条新记录,都是追加操作,都不涉及到挪动其他记录,也不会触发叶子节点的分裂。而有业务逻辑的字段做主键,则往往不容易保证有序插入,这样写数据成本相对较高。
    除了考虑性能外,我们还可以从存储空间的角度来看。假设你的表中确实有一个唯一字段,比如字符串类型的身份证号,那应该用身份证号做主键,还是用自增字段做主键呢?
    由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键,那么每个二级索引的叶子节点占用约 20 个字节,而如果用整型做主键,则只要 4 个字节,如果是长整型(bigint)则是 8 个字节。
    显然,主键长度越小,普通索引的叶子节点就越小,普通索引占用的空间也就越小。
    
    有没有什么场景适合用业务字段直接做主键的呢?还是有的。比如,有些业务的场景需求是这样的:
    1. 只有一个索引;
    2. 该索引必须是唯一索引。
    这是典型的 KV 场景。由于没有其他索引,所以也就不用考虑其他索引的叶子节点大小的问题。
    这时候我们就要优先考虑上一段提到的“尽量使用主键查询”原则,直接将这个索引设置为主键。
    
    当然在高并发负载时，主键顺序插入可能会造成明显的争用，会导致间隙锁竞争。

模糊查询是否走索引的问题：

    select * from user where name like 'j' 或 'j%' 或 '%j' 或 '%j%';
    1. like 'j' 或 'j%' 可以使用索引，并且快速定位记录，表象就是查询速度很快。
    2. like '%j' 或 '%j%'，只是在二级索引树上遍历查找记录，并不能快速定位（使用了索引，但是扫描了整棵索引树），表象就是查询速度没那么快。
    两者的区别就是“用索引”和“用索引快速定位记录”，两者都用了索引，但是第二种没有发挥索引的优势，建了索引还遍历所有的索引是低效的。

select * from data where a='1' or b = '2'; 查询语句索引匹配情况： 如果建的是a,b联合索引； 如果a，b分别建的独立索引

可以对一个列创建多个相同的索引，没有任何用处，如果有需要移除。mysql的唯一限制和主键限制都是通过索引实现的。
    
    下面这条语句会在id列上创建3个索引
    create table test(id int not null primary key, a int not null, unique(id), index(id));
    
冗余索引: 先创建索引(A,B)，再创建索引(A就是冗余索引。
    
衡量查询开销的三个指标：响应时间，扫描的行数，返回的行数

数据库在更新数据时先更新数据文件在内存的副本，并同时追加到wal(预写日志)做持久化，内存中的数据再统一做持久化。
这样每次更新数据是需要两次写入，但wal日志是追加，属于顺序写而非随机写，速度比直接修改数据文件的内容要快。
完整的更新流程是怎么样的？

innodb是一定会有主键索引的，主键索引属于聚簇索引，所以存储方式是数据行和主键索引一起存储，而不会再单独存储一份数据，
不然数据就存储了两份，浪费空间，而且更新的时候效率很低。所以innodb中，聚簇索引就是表。 
myisam的主键索引的叶子节点存放的是数据对应的行指针，所以是非聚簇索引。 innodb的二级索引存的是主键的值，而myisam的二级索引
跟主键索引一样，存的仍然是行指针。又innodb实现了mvcc,主键索引记录中会包含两个必要的列trx_id和roll_pointer。
![](./innodb_index.bmp)


条件in的查询过程，mysql将in()列表中的数据先进行排序，然后通过二分查找的方式判断每个值，比多个or条件的查询速度要快。
in查询是可以走索引的，建个简单的表测试过。 https://www.xttblog.com/?p=3651

关联查询： MySQL认为任何一个查询都是一次关联，比如关联查询A和B，固定表B，从A里面一行行的读取符合条件的，然后从B表中去匹配。
效是比较低的，如果有多层关联查询，先做底层的关联，生成临时表，再对临时表做关联。

## 高性能mysql

<深入理解 MySQL 事务隔离级别和 MVCC 原理>
https://mp.weixin.qq.com/s/Jeg8656gGtkPteYWrG5_Nw

<MySQL 是怎样运行的：从根儿上理解 MySQL>
https://juejin.im/book/5bffcbc9f265da614b11b731/section/5c0374a06fb9a049d37ed783

innodb默认隔离级别是可重复读，即一个事务当中任何时刻看到的同一行的内容是一样的，但是如果范围查找比如limit得到的结果则是可以变的，
即幻行读取(幻读)。意思就是这种隔离级别不会update已有数据，但是可以新增数据。 用串行化的隔离级别是可以的解决的，但是并发性能太低。
innodb和xtradb存储引擎通过间隙锁的方式解决幻读问题，即对索引的区间加锁。 又提到是多版本并发控制(mvcc)解决？ 

mvcc,在每一行数据增加两个隐藏字段，其中一个就是版本。是行级锁的变种，但在很多情况下避免了加锁操作。
对于使用READ UNCOMMITTED隔离级别的事务来说，直接读取记录的最新版本就好了，对于使用SERIALIZABLE隔离级别的事务来说，使用加锁的方式来访问记录。
对于使用READ COMMITTED和REPEATABLE READ隔离级别的事务来说，就需要用到我们上边所说的版本链了

在同一个数据库实例中不同的表使用不同的存储引擎是可以的。 但在同一个事务中，使用到不同的存储引擎是不可靠的，如果中间有一个存储引擎不支持事务就无法回滚。

避免null的值，因为null使得索引，索引统计和值的比较都更复杂，需要占据更多的空间。
NULL代表没有值，意味着你并不知道该列应该填入什么数据，在判断某一列是否为NULL的时候使用is

数据库支持同时提交多个事务，因为要考虑并发性能，如果这些事务之间不会访问相同的数据，那么只要解决单个事务的问题。
如果访问到相同的数据就有可能出现冲突。数据库设置了一定机制避免冲突，一个事务与其他事务隔离的程度称为隔离级别，隔离级别越高, 数据一致性就越好, 但并发性越弱

冲突可能产生的问题有：脏读，不可重复读，幻读，丢失更新。 SQL标准定义了4个隔离级别：读未提交数据，读已提交数据，可重读，可串行化。
隔离级别的实现，通过锁来解决，具体的方法： https://www.zhihu.com/question/51678508


##　redo 和　undo
　　当insert update delete操作时，数据库先修改内存中的数据(buffer),记录redo log buffer,当buffer到一定程度时才持久化，
   当buffer达到刷新条件才会对文件进行操作。redo log是顺序写入到磁盘，性能比直接随机写数据文件要高。  因为数据并没有真正的写入数据文件，
   当数据库系统崩溃后(比如断电，重启)，会利用redo log和undo log恢复数据。
   恢复的原则： 从前向后读取redo,重做所有已提交的事务；从后往前读取undo,回滚未提交的事务。
    
   每个事务的完成最重要的一个标志就是日志必须落盘，一条日志记录包括redo记录和undo记录，一个事务可能有多次的写操作，
   所以如果每写一条记录，就写一次盘，性能接受不了，所以在一个事务未提交之前，日志会写进log buffer中，在事务提交的时候或者buffer被写满的时候，
   将log刷到磁盘上，log成功落盘后事务才能应答成功，所以如果没有事务并发提交，一个事务完成，至少有一次的落盘操作为了进一步优化落盘性能，
   减少落盘次数，如果是有并发的事务提交，还可能会把并发提交的事务日志做一个合并，一次性写入到磁盘中
    
   Redo log可以简单分为以下两个部分：  https://juejin.im/post/5c3c5c0451882525487c498d
    
        一是内存中重做日志缓冲 (redo log buffer),是易失的，在内存中
        二是重做日志文件 (redo log file)，是持久的，保存在磁盘中

   
   redo流程![](./redo.bmp))
   
   undo log是逻辑日志，对事务回滚时，只是将数据库逻辑地恢复到原来的样子，而redo log是物理日志，记录的是数据页的物理变化，显然undo log不是redo log的逆过程。
   redo log(重做日志，属innodb引擎)和binlog(归档日志，server层)，而redo log用的是wal(预写日志)技术，先将日志写到缓存，然后再刷到磁盘。
   redo log 是固定大小的,比如可以配置为一组4个文件,每个文件的大小是1GB，是循环更新的。
   
   普通的非事务中的insert是否会写redo log? 在mysql中，普通的单条修改数据库的语句也是事务，对数据操作之后需要commit才生效，可以打开自动commit，所以也是有redo log的。
   
   
## 实战mysql45讲
   查询缓存往往弊大于利,查询缓存的失效非常频繁,只要有对一个表的更新,这个表上所有的查询缓存都会被清空。
   除非你的业务就是有一张静态表,很长时间才会更新一次。比如,一个系统配置表,那这张表上的查询才适合使用查询缓存。
   MySQL 8.0 版本直接将查询缓存的整块功能删掉了。
   

## Ubuntu 安装mysql
   从官网下载社区版编译好的二进制安装包，目前已到8.0版本。 解压到/usr/local/bin或其他目录下，设置好环境变量。
   
       apt-get install libaio1 安装动态库
       bin/mysqld --initialize --user=mysql  初始化data目录
       bin/mysqld_safe --user=mysql &或bin/mysqld 启动，会给root用户初始化一个随机密码
       mysqld --datadir=/home/zhg/bin/mysql/data2   密码123456　本机环境启动
       mysql -u root -p  连接数据库，　　
       alter user 'root'@'localhost' identified by 'youpassword';  修改密码
       flush privileges;    刷新权限
       
       
       create database T2;
       use T2;
       CREATE TABLE test (id INT NOT NULL primary key auto_increment, name VARCHAR( 50 ) NOT NULL);

## mysql主从集群
MySQL作为关系型数据库的一种，天然不支持分布式，不方便扩容。其集群主要是指高可用集群，比如MMM和MHA方案，实现主从复制以及主从切换。有从库保证了读的高可用，但此时写库仍然是单点
MySQL不能水平扩展的原因限制了很多应用，许多支持分布式，兼容MySQL的关系型数据库出现，比如阿里的oceanbae, 开源的TiDB.
其中TiDB底层是k-v存储，类似Hbase,对外自行实现了sql解析器和执行器，将k-v存储映射到关系型数据库。

cobar已不更新，生产环境可用的可以考虑MySQL官方的MySQL router， mycat, 阿里的tddl，
传统的分库分表本来就是非常成熟的技术，cobar等中间件只是简化了这个过程

MySQL cluster是在关系型的基础上做分布式，使得实现复杂， 读和写事务很复杂。而TiDB是先确定做分补水，然后实现关系型标准，架构上更简单。

主从架构读写：
一般可以通过设置一主多从，读写分离提升读的性能，读的时候就只读从库，但是会出现数据不一致。 不一致的原因是从库同步数据有延时。
<数据库主从不一致，怎么解？> https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651961330&idx=1&sn=4bdbada3b26d4fc2fc505f7a0f2ad7c4&chksm=bd2d022e8a5a8b38e59f0dfffba7ca407fe8711644b3794832572dd822c665205bb820cdddf7&scene=21#wechat_redirect


对于传统的主备模式或者一主多备模式，需要考虑的问题就是与备机保持强同步还是异步复制。对于强同步模式，要求主机必须把日志同步到备机之后，才能应答客户端，
一旦主备之间出现网络抖动，或者备机宕机，则主机无法继续提供服务，这种模式实现了数据的强一致，但是牺牲了服务的可用性，且由于跨机房同步延迟过大使得跨机房的主备模式也变得不实用。
而对于异步复制模式，主机写本地成功后，就可以立即应答客户端，无需等待备机应答，这样一旦主机宕机无法启动，少量不同步的日志将丢失，这种模式实现了服务持续可用，但是牺牲了数据一致性。
对于传统的主备模式或者一主多备模式，我们都需要考虑的问题，就是与备机保持强同步还是异步复制。


对于强同步模式，要求主机必须把 Redolog 同步到备机之后，才能应答客户端，一旦主备之间出现网络抖动，或者备机宕机，则主机无法继续提供服务，这种模式实现了数据的强一致，但是牺牲了服务的可用性，且由于跨机房同步延迟过大使得跨机房的主备模式也变得不实用。

而对于异步复制模式，主机写本地成功后，就可以立即应答客户端，无需等待备机应答，这样一旦主机宕机无法启动，少量不同步的日志将丢失，这种模式实现了服务持续可用，但是牺牲了数据一致性。


## mysql双主
双主也是高可用的方案，两个节点，互为主备，对外只提供一个虚拟IP(vip),写的时候随机的写入到其中一个，另外一个会进行同步，所以同步是双向的。
双主情况的数据一致性比主从架构的一致性要强，但仍然会有不一致的情况. 因为没有使用分布式一致性协议比如paxos,所有数据高可用方案都存在一致性问题，只能尽量避免，
或者牺牲一定的可用性来保证一致性。 而mongodb副本集最开始用的一致性协议bully,后续版本用的是raft的扩展。

考虑极端情况，不通过vip，而是分别直接连接节点IP同时进行操作，会怎么样？ 两边数据混合？

<保证读库的高可用，但此时写库仍然是单点> https://mp.weixin.qq.com/s/sCjzzi9VXPk-JcWXySfHgw


## 分库分表与分区
分库： 将表拆分后放到不同的库，不同的库可以在不同的数据库实例，从而实现多服务器扩展
分表： 将表拆分后仍然在同一个库，库内分表只解决了单一表数据量过大的问题，但没有将表分布到不同机器的库上，还是竞争同一个物理机的CPU、内存、网络IO，最好通过分库分表来解决。
分库分表： 即将表拆分到不同的库
分区： 数据库本身支持的功能，表的存储分为不同的文件，所有的分区文件仍然在同一台服务器上，hbase等数据库天然就是分区，并且不同分区可以在不同服务器上


分库带来的问题：

    1. 事务支持，扩库事务就成分布式的了，问题难度显然上升了一个级别
    2. 查询结果合并，比如order by/limit/查询中不带分表(partion key)字段，需要遍历所有库然后在业务代码中进行内存合并
    3. join，这个更难

分区的不足：

    分库分表是业务层实施的，需要代码支持，分区是MySQL支持的功能，MySQL从5.1版本之后开始支持。
    分区的问题有：
    分区键设计不太灵活，如果不走分区键，很容易出现全表锁。 一旦数据量上来，如果在分区表实施关联，就是一个灾难。 
    分区表在清理数据归档时非常有用，比如按天分区，比如日志存储，zabbix中的历史数据


数据库扩展：

    数据库的扩展一般可分为读的扩展、写的扩展以及数据量的扩展。
    对于读的扩展，通过复制架构，增加更多的从库，是可以大大缓解读的，而在合适的时机使用缓存架构，是普遍认为更良好的一种解决方案。
    对于写的扩展，复制架构其实无助于解决问题，如果不能从应用层减少数据的写入，我们只能进行垂直或者水平的拆分，把数据的写入平均分布到多个节点。
    对于数据量的扩展，也是水平切分，支持多节点

分库分表举例：

    看业务场景和需求，如果是1对多的情况，比如用户和帖子关系，一个用户对应多个帖子，可以根据用户id即uid分库也可以根据帖子id即tid分库，但可能点击查看帖子详情的需求多一些，
    最好的情况是对uid和tid同时切分，并且能够分到一起，使用基因法，tid的后缀和uid相同，并且相同的分库规则。 
    这样分库之后如果只根据uid和tid查询是可以快速定位，但要根据其他字段查询就需要扫描所有的库然后取到结果，
    弥补措施就是再建一张映射关系表，只有两列，可以存储很多的数据，查询也快，如果数据很多也要分表。但这样会增加一次查询，时间上也会有损耗。
    如果是多对多的场景，比如卖出的商品信息，买家需要查询卖家也需要查询，可以的方法是数据按照需求存两份，可以加快查询速度

参考：

    <数据库分库分表，何时分？怎样分？> https://juejin.im/entry/5c258e02f265da617573d346
    <五大常见的MySQL高可用方案> https://zhuanlan.zhihu.com/p/25960208
    <mysql cluster适用场景分析>： http://blog.chinaunix.net/uid-26950862-id-4573456.html
    <数据库中间件> https://www.zhihu.com/question/36758780
    <关于MySQL集群的一些看法> https://zhuanlan.zhihu.com/p/20204156
    <假如让你来设计数据库中间件> https://mp.weixin.qq.com/s/6kuVgdO7RBs9gs229wG3wA
    <数据库中间件360 Atlas调研笔记> https://mp.weixin.qq.com/s/31WOensXaLdaAp9WRMW7PA
    <业界难题-“跨库分页”的四种方案> https://mp.weixin.qq.com/s/h99sXP4mvVFsJw6Oh3aU5A
    <数据库架构设计与业务的变化> https://mp.weixin.qq.com/s/qbVrQ_aUdL9k28XVinpJXA
    <三篇文章了解 TiDB 技术内幕 - 说计算> https://pingcap.com/blog-cn/tidb-internal-2/
    <大众点评订单系统分库分表实践> https://tech.meituan.com/2016/11/18/dianping-order-db-sharding.html
    
## mysql 数据存储
启动MySQL时需要指定数据目录，该目录用于存放binlog,表数据等。每新建一个库，就会有一个与库名同名的目录。

redo/undo log是innodb层维护的，是跟存储引擎有管，而binlog是mysql server层维护的，跟采用何种引擎没有关系，
记录的是所有更新操作的日志记录(对数据库的改动),主要用于数据库的主从复制以及增量恢复。
binlog是二进制文件，可以用MySQL自带的mysqlbinlog工具查看里面的内容，mysqlbinlog --base64-output=decode-rows -v binlog.000001, 一定
要加中间的参数，不然insert语句内容看不到。 binlog中的每个语句都有一个标号以及时间。
binlog.index里面记录了所有的binlog文件。 binlog是每启动一次会新增一个，大到一定成都是会进行切分。利用binlog可以方便的进行增量备份与还原，还原的时候可以指定时间范围，要恢复的库等。
<MySQL binlog格式解析> https://www.jianshu.com/p/c16686b35807

使用innodb引擎：
ibd文件：单表表空间文件，每个表使用一个表空间文件（file per table），存放表数据和索引。无法直接解析，只能将文件拷贝到
新的数据库，新建表，然后让数据库加载之后显示。


## 其他(索引，mvcc等)
提高并发的演进思路：
普通锁，本质是串行执行
读写锁，可以实现读读并发
数据多版本，可以实现读写并发，只能一个写多个读， 写写冲突是无法避免的

InnoDB实现的mvcc做到了快照读，这种一致性不加锁的读，就是InnoDB并发如此之高的核心原因之一(加解锁的开销比较大，不用锁比用锁的并发要高)。
InnoDB结合锁策略和mvcc实现了四种隔离级别。
(1)读未提交：什么也不限制，select不加锁，但可能出现脏读，并发最高，一致性最差的隔离级别；
(2)读提交(Read Committed, RC)：普通select快照读，加锁的select(select ... in share mode / select ... for update)等语句，
除了在外键约束检查(foreign-key constraint checking)以及重复键检查(duplicate-key checking)时会封锁区间，其他时刻都只使用记录锁可能出现不可重复读；
此时，其他事务的插入依然可以执行，就可能导致，读取到幻影记录。
(3)可重复读(Repeated Read, RR)：默认的隔离级别，普通select快照读。加锁的select(select ... in share mode / select ... for update)等语句，
在唯一索引上使用唯一的查询条件，会使用记录锁(record lock);范围查询条件，会使用间隙锁与临键锁，锁住索引记录之间的范围，避免范围间插入记录，以避免产生幻影行记录；
(4)串行化：select隐式转化为select ... in share mode，会被update与delete互斥；


InnoDB的行锁是实现在索引上的，而不是锁在物理行记录上。如果访问没有命中索引，也无法使用行锁，将要退化为表锁。
    
在 InnoDB，所有的用户活动发生在一个事务。如果 autocommit 启用，则每个 SQL 语句将自行形成一个事务。默认情况下，MySQL 会为每个 autocommit 
启用的新连接启动会话，所以如果该语句没有返回错误，MySQL 将在每个 SQL 语句之后进行提交。如果语句返回错误，则提交或回滚行为取决于错误。
所以每条单独的insert语句就是一个事务，不同于START TRANSACTION等显式申明一个事务，单独的insert语句属于隐式事务，

select ** for update 中for update是显式的加锁，没有其他意思。
on duplicate key update 可以将重复的键覆盖而不是直接冲突的错 

假设表有id和name两个列，id是自增列，如下插入语句，中间会有键冲突，已被插入的数据会被留下，且后面的数据会接着插入。
INSERT IGNORE INTO test (id, name) VALUES (1,"hong"),(2, "ping"),(2,"kong"),(3,"test");
    
    实测输出：
    INSERT IGNORE INTO test (id, name) VALUES (1,"hong"),(2, "ping"),(2,"kong"),(3,"test");
    Query OK, 3 rows affected, 1 warning (0.21 sec)
    Records: 4  Duplicates: 1  Warnings: 1
    
    mysql> select * from test;
    +----+------+
    | id | name |
    +----+------+
    |  1 | hong |
    |  2 | ping |
    |  3 | test |
    
    查看autocommit是否开启： show variables like 'autocommit'\G
    关闭autocommit： set autocommit=off;
    无论是否开启，执行结果是一样的
 
参考：

    <58到家MySQL军规升级版> https://mp.weixin.qq.com/s/YfCORbcCX1hymXBCrZbAZg
    <InnoDB并发如此高，原因竟然在这？> https://mp.weixin.qq.com/s/R3yuitWpHHGWxsUcE0qIRQ
    <4种事务的隔离级别，InnoDB如何巧妙实现？> https://mp.weixin.qq.com/s/x_7E2R2i27Ci5O7kLQF0UA
    

## mysql 8.0
mysql版本从5.7直接跳到8.0，MySQL 8.0发生了巨大的变化和修改。物理文件已更改。例如，*.frm，* .TRG，*.TRN和* .par 不再存在。添加了大量的新特性，
如通用表表达式(Common Table Expressions CTE)，窗口函数（Window Functions），不可见索引（ Invisible Indexes），正则表达式（regexp）。
MySQL8.0现在已经完全支持Unicode，且具有多字节安全特性。

<MySQL性能基准测试对比：MySQL 5.7与MySQL 8.0> https://cloud.tencent.com/developer/article/1399045


## mysql中datetime

mysql日期数据类型：

    DATE 	    3字节 	1000-01-01/9999-12-31 	                   YYYY-MM-DD 	        日期值
    TIME 	    3字节 	'-838:59:59'/'838:59:59' 	               HH:MM:SS 	        时间值或持续时间
    YEAR 	    1字节 	1901/2155 	                               YYYY 	            年份值
    DATETIME 	8字节 	1000-01-01 00:00:00/9999-12-31 23:59:59    YYYY-MM-DD HH:MM:SS 	混合日期和时间值
    TIMESTAMP 	4字节 	1970-01-01 00:00:00/2038                   YYYYMMDD HHMMSS 	    混合日期和时间值，时间戳
    
    其中datetime在新版本中5字节 

TIMESTAMP和DATETIME的相同点：两者都可用来表示YYYY-MM-DD HH:MM:SS[.fraction]类型的日期。

TIMESTAMP和DATETIME的不同点：两者的存储方式不一样,对于TIMESTAMP，它把客户端插入的时间从当前时区转化为UTC进行存储。查询时，
将其又转化为客户端当前时区进行返回。而对于DATETIME，不做任何改变，基本上是原样输入和输出。

时间戳没有时区概念，时区存在主要是为了：自然时间表示时必须要有时区才有意义，否则时间是没有意义的。自然时间就是现实生活中人们所认识的时间，
计算机中的时间是时间戳，在现实生活中肯定是不方便理解的。时间的概念更倾向于时刻，它是全世界唯一的，比如现在这个时刻东八区
北京时间是：2018-1-25 15:30:30，其对应的时间戳是1516865430404，但是同样这刻在零时区时间是：2018-1-25 07:30:30，但是它的时间戳
依然是1516865430404，也就是说，计算机中的时间戳是一个时刻的概念，不存在时区区别。 同一时刻，在不同时区的timestamp是一样的，但是datetime是不一样。

如果你的应用是用于不同时区（就是国内和国外同时使用），用timestamp.
如果多系统间需要传递时间，用timestamp,因为时间戳不存在时区概念，不需要进行转换,占用的字节大小小，传输快。


postgresql日期数据类型：

    timestamp  [不带时区 ]   日期和时间(无时区)              8字节
    timestamp  [带时区 ]     日期和时间(带时区)              8字节
    date                    日期(没有时间)                 4字节
    time [ 不带时区 ]         时间(一日内的时间00:00:00-24:00:00)  8字节    
    time [ 带时区 ]          时间(带时区)                  12字节
    interval [ fields ]    时间间隔                       12字节
    
    没有datetime类型，其中的timestamp类型，在ORM中定义用的是db.DateTime，在pgadmin中看到的类型是timestamp without time zone,
    显示的字符串“2019-05-05 00:00:00”。 默认都不会显示时区，需要显示的指定with time zone
    
    按理timestamp是没有时区的，而pgsql中内部是按UTC时区存储的时间，客户端读写该数据时PostgreSQL服务器根据用户session的timezone和UTC的
    差距进行时间转换。由于并没有把原始的时区值存下来，所以PostgreSQL的“TIMESTAMP WITH TIME ZONE”其实相当于Oracle的“TIMESTAMP WITH LOCAL TIME ZONE”。
    也就是虽然是timestamp类型，但是支持insert "2019-05-05 00:00:00"方式直接插入，这个时候就会做时区的处理。
    

除了datetime和timestamp的区别另外就是UTC、CST、GMT等时区的区别。

<MySQL中有关TIMESTAMP和DATETIME的总结> https://www.cnblogs.com/ivictor/p/5028368.html


## linux时间同步
每个服务器时间不一定准时，即使最开始是准时的，中间跑着跑着就会积累很多的误差。所以需要与标准时间进行同步，
同步的协议是ntp，需要指定同步源，可以是天文台，卫星或者网络上某个标准服务器。 

系统时间是指操作系统时间，硬件时间是bios中记录的时间，硬件时钟由bios电池供电。系统开机时要读取这个时间，并根据它来设定系统时间（系统启动时
根据硬件时间设定系统时间的过程可能存在时区换算，这要视具体的系统及相关设置而定）。 这样即使服务器长期不联网不同步时间也会有一个时间，但误差会比较大。
系统启动后系统时钟就会独立于硬件时钟运行。

同步的是系统时间而非硬件时间，所以一般是系统时钟通过ntp同步之后在更新硬件时钟(可以设置定时任务定时更新硬件时钟)。 并且要设置开机自启动ntp,不然服务器一重启时间仍然有误差。
如果是不能访问外网的集群要统一时间，将其中一台作为标准时间服务器做同步源，其他服务器向这台进行同步。
即使同步，仍然会有微妙或者纳秒的差距，在分布式系统中必然要考虑。

UTC时间是世界协调时间（又称世界标准时间），在一般精度要求下，它与GMT（格林威治标准时间）是一样的，其实也就是说 GMT≈UTC，但 UTC 是以原子钟校准的，更精确。本地时间 = UTC + 时区

<Linux操作系统时间与BIOS硬件时间>  https://www.cnblogs.com/ajianbeyourself/p/4189520.html


## join优化
多个表连接查询，最进程的方式是嵌套join(nested loop join),分为内外表，每扫描外表的一行数据都要在内表中查找与之匹配的行，没有索引的 复杂度是
O(n*m). 在此基础上进行优化出现了merge join和hash join.

hash join将小表作为hash表放在内存中，加快查询速度。不过hash join只适用于等值连接。